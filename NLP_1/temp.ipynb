{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from pytube import Playlist\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#api_key = 'AIzaSyDeP_lfp2l2sr9cEPKRi5M6CpwXDUMgQ2c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:20<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All total comments obtained: 2313\n",
      "Model Prediction--->>>>\n",
      "73/73 [==============================] - 1s 13ms/step\n",
      "Total Viwes:  13449742\n",
      "Total Likes:  230582\n",
      "Total duration:  3 days, 2:08:10\n",
      "All total comments obtained: 2313\n",
      "Total Positive Comments:  2189\n",
      "Total Non-Positive Comments:  124\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog,messagebox\n",
    "from tkinter import Label\n",
    "from googleapiclient.discovery import build\n",
    "from pytube import Playlist\n",
    "import os\n",
    "import isodate\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from pytube import Playlist\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pickle\n",
    "import keras\n",
    "\n",
    "\n",
    "def nlp_model(sentence,mod):\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    if mod==\"ann\":\n",
    "        ann = keras.models.load_model(\"ann.keras\")\n",
    "        pred = ann.predict(padded)\n",
    "        return  (len(pred[(pred>=0.5)]),len(pred[(pred<0.5)]))\n",
    "    \n",
    "    else:\n",
    "        bi_lstm = keras.models.load_model(\"bi_lstm_model.keras\")\n",
    "        pred = bi_lstm.predict(padded)\n",
    "        return (len(pred[(pred>=0.5)]),len(pred[(pred<0.5)]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "\n",
    "def get_comments(youtube_object, video_id, token):\n",
    "\n",
    "  global all_comments\n",
    "  totalReplyCount = 0\n",
    "  token_reply = None\n",
    "\n",
    "  if (token == ''):\n",
    "    video_response=youtube_object.commentThreads().list(part='snippet',maxResults=100,videoId=video_id,order='relevance').execute()\n",
    "  else:\n",
    "    video_response=youtube_object.commentThreads().list(part='snippet',maxResults=100,videoId=video_id,order='relevance',pageToken=token).execute()\n",
    "\n",
    "\n",
    "  for indx, item in enumerate(video_response['items']):\n",
    "    all_comments.append(remove_html_tags(item['snippet']['topLevelComment']['snippet']['textDisplay']))\n",
    "\n",
    "    totalReplyCount = item['snippet']['totalReplyCount']\n",
    "\n",
    "  if \"nextPageToken\" in video_response:\n",
    "    return get_comments(youtube_object, video_id, video_response['nextPageToken'])\n",
    "  else:\n",
    "    all_comments = [x for x in all_comments if len(x) > 0]\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "def main_cmnt(play_list_link):\n",
    "\n",
    "  p = Playlist(play_list_link)\n",
    "  global all_comments\n",
    "  all_comments = []\n",
    "  \n",
    "  for url_input in tqdm(p):\n",
    "    video_id_split = url_input.split('=')\n",
    "    video_id=video_id_split[1]\n",
    "\n",
    "    youtube_object = build('youtube', 'v3',developerKey=api_key)\n",
    "    comments = get_comments(youtube_object,video_id,'')\n",
    "\n",
    "  # Show results:\n",
    "  df = pd.DataFrame(all_comments,columns=['Comments'])\n",
    "  df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "  df['Comments'] = df['Comments'].apply(lambda x: re.split('<a href=\"https:\\/\\/.*', str(x))[0])\n",
    "  all_comments = df['Comments'].to_list()\n",
    "  print(\"All total comments obtained: \"  + str(len(all_comments)))\n",
    "  return all_comments\n",
    "\n",
    "\n",
    "#____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "api_key = \"AIzaSyDeP_lfp2l2sr9cEPKRi5M6CpwXDUMgQ2c\"  \n",
    "youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "def convert_duration(duration):\n",
    "    # Convert ISO 8601 duration format to a timedelta object\n",
    "    duration = isodate.parse_duration(duration)\n",
    "    return duration\n",
    "\n",
    "def get_playlist_info():\n",
    "    try:\n",
    "        playlist_url = playlist_url_entry.get()\n",
    "        playlist = Playlist(playlist_url)\n",
    "        playlist_title = playlist.title\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", \"Failed to retrieve playlist data. Make sure the URL is valid.\")\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    total_views = 0\n",
    "    total_likes = 0\n",
    "    total_comments = 0\n",
    "    total_duration = isodate.parse_duration(\"PT0S\")  # Initialize total duration to 0 seconds\n",
    "    #______________________________________________________________________________________________________________________________________\n",
    "    \n",
    "    k = main_cmnt(playlist_url)\n",
    "    print(\"Model Prediction--->>>>\")\n",
    "    pos_neg = nlp_model(k,\"a\")\n",
    "    #__________________________________________________________________________________________________________________________________________________________\n",
    "    for video_url in playlist.video_urls:\n",
    "        video_id = video_url.split(\"v=\")[1]\n",
    "        request = youtube.videos().list(\n",
    "        part=\"statistics,contentDetails\",\n",
    "        id=video_id)\n",
    "        response = request.execute()\n",
    "\n",
    "        video = response[\"items\"][0]\n",
    "        total_views += int(video[\"statistics\"][\"viewCount\"])\n",
    "        total_likes += int(video[\"statistics\"][\"likeCount\"])\n",
    "        total_comments += int(video[\"statistics\"][\"commentCount\"])\n",
    "        total_duration += convert_duration(video[\"contentDetails\"][\"duration\"])\n",
    "\n",
    "\n",
    "    print('Total Viwes: ',total_views)\n",
    "    print('Total Likes: ',total_likes)\n",
    "    print('Total duration: ',total_duration)\n",
    "    print(\"All total comments obtained: \"  + str(len(all_comments)))\n",
    "    print(\"Total Positive Comments: \",pos_neg[0])\n",
    "    print(\"Total Non-Positive Comments: \",pos_neg[1])\n",
    "    #_________________________________________________________________________________________\n",
    "    #________________________________________________________________________________________________\n",
    "    playlist_info_entry.delete(0, END)\n",
    "    playlist_info_entry.insert(0, playlist_title)\n",
    "    views_entry.delete(0, END)\n",
    "    views_entry.insert(0, total_views)\n",
    "    likes_entry.delete(0, END)\n",
    "    likes_entry.insert(0, total_likes)\n",
    "    comments_entry.delete(0, END)\n",
    "    comments_entry.insert(0, total_comments)\n",
    "    duration_entry.delete(0, END)\n",
    "    duration_entry.insert(0, str(total_duration))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"YouTube Playlist Info Retrieval\")\n",
    "root.configure(bg=\"white\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Label and Entry for Playlist URL\n",
    "playlist_url_label = Label(root, text=\"Enter Playlist URL:\")\n",
    "playlist_url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "playlist_url_entry = Entry(root, width=50)\n",
    "playlist_url_entry.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "# Button to get playlist info\n",
    "get_info_button = Button(root, text=\"Go\", command=get_playlist_info, padx=5, pady=2)\n",
    "get_info_button.grid(row=1, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "# Labels and Entries for Playlist Info\n",
    "playlist_info_label = Label(root, text=\"Playlist Title:\")\n",
    "playlist_info_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "playlist_info_entry = Entry(root, width=50)\n",
    "playlist_info_entry.grid(row=3, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "views_label = Label(root, text=\"Total Views:\")\n",
    "views_label.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "views_entry = Entry(root, width=10)\n",
    "views_entry.grid(row=3, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "likes_label = Label(root, text=\"Total Likes:\")\n",
    "likes_label.grid(row=2, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "likes_entry = Entry(root, width=10)\n",
    "likes_entry.grid(row=3, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "comments_label = Label(root, text=\"Total Comments:\")\n",
    "comments_label.grid(row=4, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "comments_entry = Entry(root, width=10)\n",
    "comments_entry.grid(row=5, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "duration_label = Label(root, text=\"Total Duration:\")\n",
    "duration_label.grid(row=2, column=3, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "duration_entry = Entry(root, width=20)\n",
    "duration_entry.grid(row=3, column=3, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "pos_comments_label = Label(root, text=\"Total Positive Comments:\")\n",
    "pos_comments_label.grid(row=4, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "pos_comments_entry = Entry(root, width=10, bg=\"green\")\n",
    "pos_comments_entry.grid(row=5, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "neg_comments_label = Label(root, text=\"Total Negative Comments:\")\n",
    "neg_comments_label.grid(row=4, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "neg_comments_entry = Entry(root, width=10, bg=\"red\")\n",
    "neg_comments_entry.grid(row=5, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "benchmark_label = Label(root, text=\"Benchmark:\")\n",
    "benchmark_label.grid(row=6, column=1, pady=5, sticky=\"w\")\n",
    "\n",
    "benchmark_entry = Entry(root, width=10, bg=\"yellow\")\n",
    "benchmark_entry.grid(row=7, column=1, pady=5, sticky=\"w\")\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=WGJJIrtnfpk&list=PL9ooVrP1hQOE4KoZLUP4LgBwFH2IJCQs6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "\n",
    "\n",
    "def nlp_model(sentence,mod):\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    if mod==\"ann\":\n",
    "        ann = keras.models.load_model(\"ann.keras\")\n",
    "        pred = ann.predict(padded)\n",
    "        return  (len(pred[(pred>=0.5)]),len(pred[(pred<0.5)]))\n",
    "    \n",
    "    else:\n",
    "        bi_lstm = keras.models.load_model(\"bi_lstm_model.keras\")\n",
    "        pred = bi_lstm.predict(padded)\n",
    "        return (len(pred[(pred>=0.5)]),len(pred[(pred<0.5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2215, 98)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = nlp_model(all_comments,\"ann\")\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 1s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2189, 124)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = nlp_model(all_comments,\"a\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Viper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
